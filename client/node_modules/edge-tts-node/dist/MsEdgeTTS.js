"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.MsEdgeTTS = exports.ProsodyOptions = void 0;
const axios_1 = __importDefault(require("axios"));
const isomorphic_ws_1 = __importDefault(require("isomorphic-ws"));
const buffer_1 = require("buffer");
const randombytes_1 = __importDefault(require("randombytes"));
const OUTPUT_FORMAT_1 = require("./OUTPUT_FORMAT");
const stream_1 = require("stream");
const fs = __importStar(require("fs"));
const SecMSGec_1 = require("./SecMSGec");
const utils_1 = require("./utils");
const Headers_1 = require("./Headers");
class ProsodyOptions {
    pitch = "+0Hz";
    rate = 1.0;
    volume = 100.0;
}
exports.ProsodyOptions = ProsodyOptions;
class MsEdgeTTS {
    static wordBoundaryEnabled = true;
    static OUTPUT_FORMAT = OUTPUT_FORMAT_1.OUTPUT_FORMAT;
    static TRUSTED_CLIENT_TOKEN = "6A5AA1D4EAFF4E9FB37E23D68491D6F4";
    static BINARY_DELIM = "Path:audio\r\n";
    static VOICE_LANG_REGEX = /\w{2}-\w{2}/;
    _enableLogger;
    _isBrowser;
    _ws;
    _voice;
    _voiceLocale;
    _outputFormat;
    _streams = {};
    _startTime = 0;
    _agent;
    _headers = null;
    _arraybuffer = false;
    state = {
        offsetCompensation: 0,
        lastDurationOffset: 0
    };
    static getVoicesUrl() {
        const param = (0, SecMSGec_1.generateSecMSGecParam)(MsEdgeTTS.TRUSTED_CLIENT_TOKEN);
        return `https://speech.platform.bing.com/consumer/speech/synthesize/readaloud/voices/list?trustedclienttoken=${MsEdgeTTS.TRUSTED_CLIENT_TOKEN}${param}`;
    }
    static getSynthUrl() {
        const param = (0, SecMSGec_1.generateSecMSGecParam)(MsEdgeTTS.TRUSTED_CLIENT_TOKEN);
        return `wss://speech.platform.bing.com/consumer/speech/synthesize/readaloud/edge/v1?TrustedClientToken=${MsEdgeTTS.TRUSTED_CLIENT_TOKEN}${param}`;
    }
    _log(...o) {
        if (this._enableLogger) {
            o.unshift('edgetts:');
            console.log(...o);
        }
    }
    static setToken(token) {
        MsEdgeTTS.TRUSTED_CLIENT_TOKEN = token;
    }
    constructor({ agent = undefined, headers = null, enableLogger = false }) {
        this._agent = agent;
        this._headers = headers || {
            headers: Headers_1.WSS_HEADERS
        };
        this._enableLogger = enableLogger;
        this._isBrowser = typeof window !== "undefined" && typeof window.document !== "undefined";
    }
    async _send(message) {
        for (let i = 1; i <= 3 && this._ws.readyState !== this._ws.OPEN; i++) {
            if (i == 1) {
                this._startTime = Date.now();
            }
            this._log("connecting: ", i);
            await this._initClient();
        }
        this._ws.send(message, () => {
            //this._log("<- sent message: ", message);
        });
    }
    _initClient() {
        this._ws = this._isBrowser
            ? new isomorphic_ws_1.default(MsEdgeTTS.getSynthUrl())
            : new isomorphic_ws_1.default(MsEdgeTTS.getSynthUrl(), { agent: this._agent, ...this._headers });
        if (this._arraybuffer)
            this._ws.binaryType = "arraybuffer";
        return new Promise((resolve, reject) => {
            this._ws.onopen = () => {
                this._log("Connected in", (Date.now() - this._startTime) / 1000, "seconds");
                this._send(`Content-Type:application/json; charset=utf-8\r\nPath:speech.config\r\n\r\n
                    {
                        "context": {
                            "synthesis": {
                                "audio": {
                                    "metadataoptions": {
                                        "sentenceBoundaryEnabled": "false",
                                        "wordBoundaryEnabled": "${MsEdgeTTS.wordBoundaryEnabled}"
                                    },
                                    "outputFormat": "${this._outputFormat}" 
                                }
                            }
                        }
                    }
                `).then(resolve);
            };
            this._ws.onmessage = (m) => {
                let mdata = m.data;
                if (typeof mdata === 'string') {
                    const encodedData = buffer_1.Buffer.from(mdata, 'utf8');
                    const message = mdata;
                    const requestId = /X-RequestId:(.*?)\r\n/gm.exec(message)[1];
                    let [headers, data] = (0, utils_1.getHeadersAndData)(encodedData, encodedData.indexOf("\r\n\r\n"));
                    const path = headers['Path'];
                    if (path === "audio.metadata") {
                        let parsedMetadata = (0, utils_1.parseMetadata)(data, this.state["offsetCompensation"]);
                        this._pushData(parsedMetadata, requestId);
                        // 更新上一次的持续时间偏移量，用于下一次 SSML 请求
                        this.state["lastDurationOffset"] = parsedMetadata["offset"] + parsedMetadata["duration"];
                    }
                    else if (path === "turn.end") {
                        this.state["offsetCompensation"] = this.state["lastDurationOffset"];
                        this.state["offsetCompensation"] += 8750000;
                    }
                    else if (path !== "response" && path !== "turn.start") {
                        // 如果路径不是 "response" 或 "turn.start"
                        throw new Error("Unknown path received"); // 抛出未知响应错误
                    }
                }
                else if (buffer_1.Buffer.isBuffer(mdata)) {
                    const message = mdata.toString();
                    const requestId = /X-RequestId:(.*?)\r\n/gm.exec(message)[1];
                    const headerLength = mdata.readUInt16BE(0);
                    if (headerLength > mdata.length) {
                        throw new Error("The header length is greater than the length of the data.");
                    }
                    // Parse the headers and data from the binary message.
                    let [headers, data] = (0, utils_1.getHeadersAndData)(mdata, headerLength);
                    if (headers['Path'] !== 'audio') {
                        throw new Error("Received binary message, but the path is not audio.");
                    }
                    const contentType = headers['Content-Type'];
                    if (contentType !== 'audio/mpeg' && contentType !== undefined) {
                        throw new Error("Received binary message, but with an unexpected Content-Type.");
                    }
                    // We only allow no Content-Type if there is no data.
                    if (contentType === undefined) {
                        if (data.length === 0) {
                            return;
                        }
                        // If the data is not empty, then we need to raise an exception.
                        throw new Error("Received binary message with no Content-Type, but with data.");
                    }
                    // If the data is empty now, then we need to raise an exception.
                    if (data.length === 0) {
                        throw new Error("Received binary message, but it is missing the audio data.");
                    }
                    this._pushData({ type: "audio", data: data }, requestId);
                }
                else {
                    mdata = buffer_1.Buffer.isBuffer(mdata) ? mdata : mdata['data'];
                    const buffer = buffer_1.Buffer.from(mdata);
                    const message = buffer.toString();
                    const requestId = /X-RequestId:(.*?)\r\n/gm.exec(message)[1];
                    this._log(message.includes("Path:audio"), buffer_1.Buffer.isBuffer(mdata), mdata instanceof ArrayBuffer);
                    if (message.includes("Path:turn.start")) {
                        // start of turn, ignore
                    }
                    else if (message.includes("Path:turn.end")) {
                        // end of turn, close stream
                        this._streams[requestId].push(null);
                    }
                    else if (message.includes("Path:response")) {
                        // context response, ignore
                    }
                    else if (message.includes("Path:audio") && buffer_1.Buffer.isBuffer(mdata)) {
                        this._pushAudioData(buffer, requestId);
                    }
                    else {
                        //this._log("UNKNOWN MESSAGE", message);
                    }
                }
            };
            this._ws.onclose = () => {
                this._log("disconnected after:", (Date.now() - this._startTime) / 1000, "seconds");
                for (const requestId in this._streams) {
                    this._streams[requestId].push(null);
                }
            };
            this._ws.onerror = (error) => {
                this._log(error);
                let errorMessage;
                if (typeof error === "object" && error !== null) {
                    try {
                        errorMessage = JSON.stringify(error);
                    }
                    catch (e) {
                        errorMessage = error + "";
                    }
                }
                else {
                    errorMessage = error + "";
                }
                reject("Connect Error: " + errorMessage);
            };
        });
    }
    _pushData(data, requestId) {
        data = typeof data == "string" ? data : JSON.stringify(data);
        this._streams[requestId].push(data, 'utf8');
    }
    _pushAudioData(audioBuffer, requestId) {
        const audioStartIndex = audioBuffer.indexOf(MsEdgeTTS.BINARY_DELIM) + MsEdgeTTS.BINARY_DELIM.length;
        const audioData = audioBuffer.subarray(audioStartIndex);
        this._streams[requestId].push(audioData);
        this._log("_pushAudioData: received audio chunk, size: ", audioData?.length);
    }
    _SSMLTemplate(input, options = {}) {
        // in case future updates to the edge API block these elements, we'll be concatenating strings.
        options = { ...new ProsodyOptions(), ...options };
        return `<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="https://www.w3.org/2001/mstts" xml:lang="${this._voiceLocale}">
                <voice name="${this._voice}">
                    <prosody pitch="${options.pitch}" rate="${options.rate}" volume="${options.volume}">
                        ${input}
                    </prosody> 
                </voice>
            </speak>`;
    }
    getVoices() {
        return new Promise((resolve, reject) => {
            axios_1.default.get(MsEdgeTTS.getVoicesUrl())
                .then((res) => resolve(res.data))
                .catch(reject);
        });
    }
    setConfig(conf) {
        this._arraybuffer = conf["arraybuffer"] ?? false;
    }
    async setMetadata(voiceName, outputFormat, voiceLocale) {
        const oldVoice = this._voice;
        const oldVoiceLocale = this._voiceLocale;
        const oldOutputFormat = this._outputFormat;
        this._voice = voiceName;
        this._voiceLocale = voiceLocale;
        if (!this._voiceLocale) {
            const voiceLangMatch = MsEdgeTTS.VOICE_LANG_REGEX.exec(this._voice);
            if (!voiceLangMatch)
                throw new Error("Could not infer voiceLocale from voiceName!");
            this._voiceLocale = voiceLangMatch[0];
        }
        this._outputFormat = outputFormat;
        const changed = oldVoice !== this._voice
            || oldVoiceLocale !== this._voiceLocale
            || oldOutputFormat !== this._outputFormat;
        // create new client
        if (changed || this._ws.readyState !== this._ws.OPEN) {
            this._startTime = Date.now();
            await this._initClient();
        }
    }
    _metadataCheck() {
        if (!this._ws)
            throw new Error("Speech synthesis not configured yet. Run setMetadata before calling toStream or toFile.");
    }
    close() {
        this._ws.close();
    }
    toFile(path, input, options) {
        return this._rawSSMLRequestToFile(path, this._SSMLTemplate(input, options));
    }
    toStream(input, options) {
        const { stream } = this._rawSSMLRequest(this._SSMLTemplate(input, options));
        return stream;
    }
    rawToFile(path, requestSSML) {
        return this._rawSSMLRequestToFile(path, requestSSML);
    }
    rawToStream(requestSSML) {
        const { stream } = this._rawSSMLRequest(requestSSML);
        return stream;
    }
    _rawSSMLRequestToFile(path, requestSSML) {
        return new Promise(async (resolve, reject) => {
            const { stream, requestId } = this._rawSSMLRequest(requestSSML);
            const writableFile = stream.pipe(fs.createWriteStream(path));
            writableFile.once("close", async () => {
                if (writableFile.bytesWritten > 0) {
                    resolve(path);
                }
                else {
                    fs.unlinkSync(path);
                    reject("No audio data received");
                }
            });
            stream.on("error", (e) => {
                stream.destroy();
                reject(e);
            });
        });
    }
    _rawSSMLRequest(requestSSML) {
        this._metadataCheck();
        const requestId = (0, randombytes_1.default)(16).toString("hex");
        const request = `X-RequestId:${requestId}\r\nContent-Type:application/ssml+xml\r\nPath:ssml\r\n\r\n
                ` + requestSSML.trim();
        // https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-synthesis-markup
        const self = this;
        const stream = new stream_1.Readable({
            read() {
            },
            destroy(error, callback) {
                self._log("stream error:: ", error);
                delete self._streams[requestId];
                callback(error);
            },
        });
        this._streams[requestId] = stream;
        this._send(request).then();
        return { stream, requestId };
    }
}
exports.MsEdgeTTS = MsEdgeTTS;
